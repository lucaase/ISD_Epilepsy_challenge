{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])  # Use the last output of the sequence\n",
    "        return out\n",
    "\n",
    "# Define the dimensions\n",
    "input_size = 2  # Number of features (electrodes)\n",
    "sequence_length = 2000  # Length of the sequence\n",
    "hidden_size = 64  # Hidden size of the LSTM\n",
    "num_classes = 2  # Number of output classes\n",
    "\n",
    "# Reshape the data\n",
    "X_train_reshaped = basal_windows.reshape((-1, sequence_length, input_size))\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "tensor_X_train = torch.Tensor(X_train_reshaped)\n",
    "tensor_y_train = torch.Tensor(y_train)\n",
    "\n",
    "# Create Tensor datasets\n",
    "train_data = torch.utils.data.TensorDataset(tensor_X_train, tensor_y_train)\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 16\n",
    "\n",
    "# Create the data loader\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize the LSTM model\n",
    "model = LSTMModel(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "num_epochs = 100\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).long()  # Convert labels to LongTensor\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print the loss\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
