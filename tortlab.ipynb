{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Import the packages"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Before running your first cell, make sure GPU is enabled! Click the three dots in the upper right, go to 'Accelerator' and select 'GPU P100'"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T13:09:06.973644Z","iopub.status.busy":"2023-08-29T13:09:06.973267Z","iopub.status.idle":"2023-08-29T13:09:15.566602Z","shell.execute_reply":"2023-08-29T13:09:15.565236Z","shell.execute_reply.started":"2023-08-29T13:09:06.973608Z"},"trusted":true},"outputs":[],"source":["%matplotlib ipympl\n","\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","from torch import nn\n","from torch.utils.data import TensorDataset, DataLoader\n","from sklearn.preprocessing import RobustScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n","from inception import Inception, InceptionBlock\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Load and preprocess the training data"]},{"cell_type":"code","execution_count":3,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-08-29T13:09:46.551781Z","iopub.status.busy":"2023-08-29T13:09:46.551313Z","iopub.status.idle":"2023-08-29T13:09:46.750010Z","shell.execute_reply":"2023-08-29T13:09:46.748745Z","shell.execute_reply.started":"2023-08-29T13:09:46.551717Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(3, 2, 240000)\n","(3, 2, 60000)\n","(2, 720000)\n","(2, 180000)\n"]}],"source":["# Loading the data files from Kaggle into this workspace\n","basal_train = np.load('basal_train.npy')\n","pre_seizure_train = np.load('pre_seizure_train.npy')\n","\n","# Checking the dimensions of our data\n","print(basal_train.shape)\n","print(pre_seizure_train.shape)\n","\n","# Original train data is 3x2x24000, 3 subjects, 2 electrodes and 240 seconds\n","# Below we will concatenate across subjects\n","\n","# Reshape basal_train to a 2x72000 matrix (2 electrodes, 720 seconds of data)\n","basal_train_reshaped = basal_train.reshape((basal_train.shape[1], -1))\n","pre_seizure_train_reshaped = pre_seizure_train.reshape((pre_seizure_train.shape[1], -1))\n","\n","# Check the dimensions of basal_train_reshaped\n","print(basal_train_reshaped.shape)\n","print(pre_seizure_train_reshaped.shape)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Slice data into 2s segments"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T13:14:30.000473Z","iopub.status.busy":"2023-08-29T13:14:29.999494Z","iopub.status.idle":"2023-08-29T13:14:30.008477Z","shell.execute_reply":"2023-08-29T13:14:30.007234Z","shell.execute_reply.started":"2023-08-29T13:14:30.000429Z"},"trusted":true},"outputs":[],"source":["# Create a function to receive longer segments of data and divide it into smaller blocks\n","\n","# The function receives the data variable, the size of the smaller blocks it will be divided into\n","# and the related training labels (which tell whether that block is pre-epileptic or not)\n","def create_windows_per_recording(data, window_size, label):\n","    # Initialize the variables\n","    windows = []\n","    labels = []\n","    \n","    # Compute the number of windows based on the length of the data and the size of the window\n","    num_windows = (data.shape[1] - window_size) // window_size + 1\n","    for i in range(num_windows):\n","        # Fill the windows with segments of the original data\n","        window = data[:, i * window_size : i * window_size + window_size]\n","        windows.append(window)\n","        labels.append(label)\n","        \n","    # Return the resulting smaller windows and its labels\n","    return np.array(windows), np.array(labels)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Balance the labels 50/50"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T13:15:09.544519Z","iopub.status.busy":"2023-08-29T13:15:09.543640Z","iopub.status.idle":"2023-08-29T13:15:09.559610Z","shell.execute_reply":"2023-08-29T13:15:09.558191Z","shell.execute_reply.started":"2023-08-29T13:15:09.544475Z"},"trusted":true},"outputs":[],"source":["# Creates a function to subsample an imbalanced dataset and enforce a 50/50 label distribution\n","\n","# The function receives your X and y train-validation datasets and returns a subsampled version of them\n","def balance_labels(X_train, X_val, y_train, y_val):\n","    # Calculate the number of pre-epileptic samples\n","    num_pre_epileptic_train = np.sum(y_train == 1)\n","    num_pre_epileptic_val = np.sum(y_val == 1)\n","    \n","    # Calculate the number of desired basal samples\n","    desired_num_basal_train = num_pre_epileptic_train\n","    desired_num_basal_val= num_pre_epileptic_val\n","\n","    # Select the basal samples for the train set\n","    basal_train_indices = np.where(y_train == 0)[0]\n","    \n","    # Select the basal samples for the validation set\n","    basal_val_indices = np.where(y_val == 0)[0]\n","\n","    # Randomly subsample the basal indices\n","    selected_basal_train_indices = np.random.choice(basal_train_indices, size=desired_num_basal_train, replace=False)\n","    selected_basal_val_indices = np.random.choice(basal_val_indices, size=desired_num_basal_val, replace=False)\n","    \n","    # Get the pre-epileptic sample indices\n","    selected_pre_epileptic_train_indices = np.where(y_train == 1)[0]\n","    selected_pre_epileptic_val_indices = np.where(y_val == 1)[0]\n","\n","    # Combine the selected pre-epileptic and basal windows for the validation set\n","    selected_train_indices = np.concatenate([selected_pre_epileptic_train_indices, selected_basal_train_indices])\n","    \n","    # Combine the selected pre-epileptic and basal windows for the validation set\n","    selected_val_indices = np.concatenate([selected_pre_epileptic_val_indices, selected_basal_val_indices])\n","\n","    # Update the training and validation sets\n","    X_val = X_val[selected_val_indices]\n","    y_val = y_val[selected_val_indices]\n","\n","    # Update the training and validation sets\n","    X_train = X_train[selected_train_indices]\n","    y_train = y_train[selected_train_indices]\n","\n","    return X_train, X_val, y_train, y_val\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Set parameters and split train-test data\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T13:16:48.028231Z","iopub.status.busy":"2023-08-29T13:16:48.027598Z","iopub.status.idle":"2023-08-29T13:16:48.309141Z","shell.execute_reply":"2023-08-29T13:16:48.307828Z","shell.execute_reply.started":"2023-08-29T13:16:48.028162Z"},"trusted":true},"outputs":[],"source":["# Parameters\n","window_size = 2000  # equivalent to two seconds of data, equal to the test samples\n","\n","# Create windows\n","# Assign '0' to the basal (non pre-epileptic) data and '1' to pre-epileptic\n","basal_windows, basal_labels = create_windows_per_recording(basal_train_reshaped, window_size, 0) \n","pre_seizure_windows, pre_seizure_labels = create_windows_per_recording(pre_seizure_train_reshaped, window_size, 1)\n","\n","# Concatenate the training windows and their labels\n","X_train = np.concatenate([basal_windows, pre_seizure_windows])\n","y_train = np.concatenate([basal_labels, pre_seizure_labels])\n","# remove the singleton dimension\n","X_train = np.squeeze(X_train)\n","y_train = np.squeeze(y_train)\n","\n","##### Data augmentations #####\n","\n","# Artificially create \"new\" samples by slightly modifying the originals\n","\n","# Noise\n","noise = np.random.normal(0, 0.05, X_train.shape)\n","aug_noise = X_train + noise\n","\n","# Scaling\n","scaling_factor = np.random.uniform(0.5, 1.5)\n","aug_scale = X_train * scaling_factor\n","\n","# Flipping\n","aug_flipped = X_train[:, ::-1]\n","\n","###############################\n","\n","# Append augmented data to original training dataset\n","X_train = np.concatenate([X_train, aug_noise, aug_scale, aug_flipped])\n","y_train = np.concatenate([y_train, y_train, y_train, y_train])\n","\n","\n","# Split data into training and validation sets \n","# 'test_size' specifies % of data towards validation set, 0.2 = 20%\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=70)\n","\n","# Balance the training and validation set labels\n","X_train, X_val, y_train, y_val = balance_labels(X_train, X_val, y_train, y_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Scaling the data \n","# Scaling can help the model overcome changes in magnitude that do not contain information about the target\n","# However, if amplitude variations contain informations about the target, this will be detrimental to the model\n","\"\"\" scaler = RobustScaler()\n","X_train = X_train.reshape(-1, X_train.shape[-1])\n","X_train = scaler.fit_transform(X_train)\n","X_train = X_train.reshape(-1, 2, 2000)\n","X_val = X_val.reshape(-1, X_val.shape[-1])\n","X_val = scaler.transform(X_val)\n","X_val = X_val.reshape(-1, 2, 2000) \"\"\""]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T13:18:32.274443Z","iopub.status.busy":"2023-08-29T13:18:32.274024Z","iopub.status.idle":"2023-08-29T13:18:32.288319Z","shell.execute_reply":"2023-08-29T13:18:32.286698Z","shell.execute_reply.started":"2023-08-29T13:18:32.274400Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train shape:  (608, 2, 2000)\n","y_train shape:  (608,)\n","X_val shape:  (112, 2, 2000)\n","y_val shape:  (112,)\n","Number of pre-epileptic windows in the training set:  304\n","Number of basal windows in the training set:  304\n","Number of pre-epileptic windows in the validation set:  56\n","Number of basal windows in the validation set:  56\n","Proportion of pre-epileptic windows in the training set:  0.5\n","Proportion of basal windows in the training set:  0.5\n","Proportion of pre-epileptic windows in the validation set:  0.5\n","Proportion of basal windows in the validation set:  0.5\n"]}],"source":["# print the shapes of the data\n","print(\"X_train shape: \", X_train.shape)\n","print(\"y_train shape: \", y_train.shape)\n","print(\"X_val shape: \", X_val.shape)\n","print(\"y_val shape: \", y_val.shape)\n","\n","# Print the number of pre-epileptic and basal windows in the training and validation sets\n","print(\"Number of pre-epileptic windows in the training set: \", np.sum(y_train == 1))\n","print(\"Number of basal windows in the training set: \", np.sum(y_train == 0))\n","\n","print(\"Number of pre-epileptic windows in the validation set: \", np.sum(y_val == 1))\n","print(\"Number of basal windows in the validation set: \", np.sum(y_val == 0))\n","\n","# Print the proportions of pre-epileptic and basal windows in the training and validation sets\n","print(\"Proportion of pre-epileptic windows in the training set: \", np.sum(y_train == 1) / len(y_train))\n","print(\"Proportion of basal windows in the training set: \", np.sum(y_train == 0) / len(y_train))\n","\n","print(\"Proportion of pre-epileptic windows in the validation set: \", np.sum(y_val == 1) / len(y_val))\n","print(\"Proportion of basal windows in the validation set: \", np.sum(y_val == 0) / len(y_val))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Transform the data into Pytorch datasets and loaders"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T13:19:19.521249Z","iopub.status.busy":"2023-08-29T13:19:19.520806Z","iopub.status.idle":"2023-08-29T13:19:19.544096Z","shell.execute_reply":"2023-08-29T13:19:19.542822Z","shell.execute_reply.started":"2023-08-29T13:19:19.521212Z"},"trusted":true},"outputs":[],"source":["# Convert data to PyTorch tensors (a data structure)\n","tensor_x_train = torch.Tensor(X_train) \n","tensor_x_val = torch.Tensor(X_val) \n","tensor_y_train = torch.Tensor(y_train)\n","tensor_y_val = torch.Tensor(y_val)\n","\n","# Create Tensor datasets\n","train_data = TensorDataset(tensor_x_train, tensor_y_train)\n","val_data = TensorDataset(tensor_x_val, tensor_y_val)\n","\n","# Dataloaders (to feed the data into the model during training)\n","# 'batch_size' defines the chunk size of data to be fed in each training step\n","batch_size = 64\n","train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n","val_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size, drop_last=True)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T13:19:04.147100Z","iopub.status.busy":"2023-08-29T13:19:04.146326Z","iopub.status.idle":"2023-08-29T13:19:04.153304Z","shell.execute_reply":"2023-08-29T13:19:04.152123Z","shell.execute_reply.started":"2023-08-29T13:19:04.147055Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([112, 2, 2000]) torch.Size([112])\n","torch.Size([608, 2, 2000]) torch.Size([608])\n"]}],"source":["print(tensor_x_val.shape,tensor_y_val.shape)\n","print(tensor_x_train.shape,tensor_y_train.shape)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Check if the dataloader is functioning properly"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T13:19:21.734919Z","iopub.status.busy":"2023-08-29T13:19:21.734174Z","iopub.status.idle":"2023-08-29T13:19:21.746642Z","shell.execute_reply":"2023-08-29T13:19:21.745132Z","shell.execute_reply.started":"2023-08-29T13:19:21.734877Z"},"trusted":true},"outputs":[],"source":["train_iter = iter(train_loader)\n","try:\n","    data, label = next(train_iter)\n","except StopIteration:\n","    print(\"The train_loader is empty.\")\n","    \n","val_iter = iter(val_loader)\n","try:\n","    data, label = next(val_iter)\n","except StopIteration:\n","    print(\"The val_loader is empty.\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Build the model"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## InceptionTime model"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T13:26:40.520027Z","iopub.status.busy":"2023-08-29T13:26:40.519248Z","iopub.status.idle":"2023-08-29T13:26:40.556719Z","shell.execute_reply":"2023-08-29T13:26:40.555465Z","shell.execute_reply.started":"2023-08-29T13:26:40.519981Z"},"trusted":true},"outputs":[],"source":["class Flatten(nn.Module):\n","\tdef __init__(self, out_features):\n","\t\tsuper(Flatten, self).__init__()\n","\t\tself.output_dim = out_features\n","\n","\tdef forward(self, x):\n","\t\treturn x.view(-1, self.output_dim)\n","    \n","class Reshape(nn.Module):\n","\tdef __init__(self, out_shape):\n","\t\tsuper(Reshape, self).__init__()\n","\t\tself.out_shape = out_shape\n","\n","\tdef forward(self, x):\n","\t\treturn x.view(-1, *self.out_shape)\n","\n","InceptionTime = nn.Sequential(\n","                    Reshape(out_shape=(2,2000)),\n","                    InceptionBlock(\n","                        in_channels=2, \n","                        n_filters=32, \n","                        kernel_sizes=[5, 11, 23],\n","                        bottleneck_channels=32,\n","                        use_residual=True,\n","                        activation=nn.ReLU()\n","                    ),\n","                    nn.Dropout(0.2),\n","                    InceptionBlock(\n","                        in_channels=32*4, \n","                        n_filters=32, \n","                        kernel_sizes=[5, 11, 23],\n","                        bottleneck_channels=32,\n","                        use_residual=True,\n","                        activation=nn.ReLU()\n","                    ),\n","                    nn.Dropout(0.2),\n","                    nn.AdaptiveAvgPool1d(output_size=1),\n","                    Flatten(out_features=32*4*1),\n","                    nn.Linear(in_features=4*32*1, out_features=1),\n","        )"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Train the model"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T13:29:53.093558Z","iopub.status.busy":"2023-08-29T13:29:53.093062Z","iopub.status.idle":"2023-08-29T13:35:58.695457Z","shell.execute_reply":"2023-08-29T13:35:58.692832Z","shell.execute_reply.started":"2023-08-29T13:29:53.093519Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1, Training Loss: 0.6713345845540365, Validation Loss: 0.5650309324264526\n","Epoch 1, Training Accuracy: 0.5659722222222222, Validation Accuracy: 0.71875\n","Epoch 2, Training Loss: 0.6123920546637641, Validation Loss: 0.5178772211074829\n","Epoch 2, Training Accuracy: 0.6649305555555556, Validation Accuracy: 0.734375\n","Epoch 3, Training Loss: 0.5659895804193285, Validation Loss: 0.5403642654418945\n","Epoch 3, Training Accuracy: 0.6979166666666666, Validation Accuracy: 0.640625\n","Epoch 4, Training Loss: 0.5684597790241241, Validation Loss: 0.49397292733192444\n","Epoch 4, Training Accuracy: 0.6979166666666666, Validation Accuracy: 0.8125\n","Epoch 5, Training Loss: 0.5353647271792094, Validation Loss: 0.6123940944671631\n","Epoch 5, Training Accuracy: 0.7326388888888888, Validation Accuracy: 0.671875\n","Epoch 6, Training Loss: 0.5531839032967886, Validation Loss: 0.43642809987068176\n","Epoch 6, Training Accuracy: 0.7152777777777778, Validation Accuracy: 0.8125\n","Epoch 7, Training Loss: 0.511851128604677, Validation Loss: 0.4667730927467346\n","Epoch 7, Training Accuracy: 0.7552083333333334, Validation Accuracy: 0.78125\n","Epoch 8, Training Loss: 0.5077751146422492, Validation Loss: 0.5199428796768188\n","Epoch 8, Training Accuracy: 0.7326388888888888, Validation Accuracy: 0.75\n","Epoch 9, Training Loss: 0.4854406217734019, Validation Loss: 0.4786650538444519\n","Epoch 9, Training Accuracy: 0.7725694444444444, Validation Accuracy: 0.75\n","Epoch 10, Training Loss: 0.5026547279622819, Validation Loss: 0.408366322517395\n","Epoch 10, Training Accuracy: 0.7482638888888888, Validation Accuracy: 0.859375\n","Epoch 11, Training Loss: 0.46926462319162154, Validation Loss: 0.6085071563720703\n","Epoch 11, Training Accuracy: 0.7465277777777778, Validation Accuracy: 0.75\n","Epoch 12, Training Loss: 0.47749511731995475, Validation Loss: 0.5175599455833435\n","Epoch 12, Training Accuracy: 0.7708333333333334, Validation Accuracy: 0.75\n","Epoch 13, Training Loss: 0.47501527269681293, Validation Loss: 0.384941041469574\n","Epoch 13, Training Accuracy: 0.7760416666666666, Validation Accuracy: 0.84375\n","Epoch 14, Training Loss: 0.4651039176517063, Validation Loss: 0.47223955392837524\n","Epoch 14, Training Accuracy: 0.7864583333333334, Validation Accuracy: 0.8125\n","Epoch 15, Training Loss: 0.4500005775027805, Validation Loss: 0.537846028804779\n","Epoch 15, Training Accuracy: 0.7847222222222222, Validation Accuracy: 0.71875\n","Epoch 16, Training Loss: 0.45451661944389343, Validation Loss: 0.516912579536438\n","Epoch 16, Training Accuracy: 0.8038194444444444, Validation Accuracy: 0.75\n","Epoch 17, Training Loss: 0.44420992334683734, Validation Loss: 0.39762547612190247\n","Epoch 17, Training Accuracy: 0.7934027777777778, Validation Accuracy: 0.875\n","Epoch 18, Training Loss: 0.4415499336189694, Validation Loss: 0.46053943037986755\n","Epoch 18, Training Accuracy: 0.8072916666666666, Validation Accuracy: 0.796875\n","Epoch 19, Training Loss: 0.45473698443836635, Validation Loss: 0.5004815459251404\n","Epoch 19, Training Accuracy: 0.7847222222222222, Validation Accuracy: 0.78125\n","Epoch 20, Training Loss: 0.4081290264924367, Validation Loss: 0.42051932215690613\n","Epoch 20, Training Accuracy: 0.8142361111111112, Validation Accuracy: 0.84375\n","Epoch 21, Training Loss: 0.39732809530364144, Validation Loss: 0.4175010621547699\n","Epoch 21, Training Accuracy: 0.8472222222222222, Validation Accuracy: 0.859375\n","Epoch 22, Training Loss: 0.38833532068464494, Validation Loss: 0.4095121920108795\n","Epoch 22, Training Accuracy: 0.8263888888888888, Validation Accuracy: 0.796875\n","Epoch 23, Training Loss: 0.39419784479671055, Validation Loss: 0.4324324131011963\n","Epoch 23, Training Accuracy: 0.8177083333333334, Validation Accuracy: 0.765625\n","Epoch 24, Training Loss: 0.3624922103352017, Validation Loss: 0.3767791986465454\n","Epoch 24, Training Accuracy: 0.84375, Validation Accuracy: 0.84375\n","Epoch 25, Training Loss: 0.3885583778222402, Validation Loss: 0.46558913588523865\n","Epoch 25, Training Accuracy: 0.8402777777777778, Validation Accuracy: 0.765625\n","Epoch 26, Training Loss: 0.364870097902086, Validation Loss: 0.44301480054855347\n","Epoch 26, Training Accuracy: 0.8385416666666666, Validation Accuracy: 0.8125\n","Epoch 27, Training Loss: 0.39134423269165886, Validation Loss: 0.6034152507781982\n","Epoch 27, Training Accuracy: 0.8315972222222222, Validation Accuracy: 0.703125\n","Epoch 28, Training Loss: 0.41586918632189435, Validation Loss: 0.4600721597671509\n","Epoch 28, Training Accuracy: 0.8090277777777778, Validation Accuracy: 0.78125\n","Epoch 29, Training Loss: 0.38833102583885193, Validation Loss: 0.3866579532623291\n","Epoch 29, Training Accuracy: 0.8246527777777778, Validation Accuracy: 0.796875\n","Epoch 30, Training Loss: 0.3378583722644382, Validation Loss: 0.47546225786209106\n","Epoch 30, Training Accuracy: 0.8663194444444444, Validation Accuracy: 0.75\n","Epoch 31, Training Loss: 0.35571077797147965, Validation Loss: 0.4976857900619507\n","Epoch 31, Training Accuracy: 0.8368055555555556, Validation Accuracy: 0.765625\n","Epoch 32, Training Loss: 0.3684903085231781, Validation Loss: 0.4866427779197693\n","Epoch 32, Training Accuracy: 0.8315972222222222, Validation Accuracy: 0.78125\n","Epoch 33, Training Loss: 0.35973503854539657, Validation Loss: 0.31802064180374146\n","Epoch 33, Training Accuracy: 0.8298611111111112, Validation Accuracy: 0.890625\n","Epoch 34, Training Loss: 0.3720228473345439, Validation Loss: 0.4054344892501831\n","Epoch 34, Training Accuracy: 0.8246527777777778, Validation Accuracy: 0.8125\n","Epoch 35, Training Loss: 0.3418526351451874, Validation Loss: 0.2581433653831482\n","Epoch 35, Training Accuracy: 0.8697916666666666, Validation Accuracy: 0.9375\n","Epoch 36, Training Loss: 0.3331458866596222, Validation Loss: 0.36834850907325745\n","Epoch 36, Training Accuracy: 0.8697916666666666, Validation Accuracy: 0.84375\n","Epoch 37, Training Loss: 0.32784589131673175, Validation Loss: 0.39290690422058105\n","Epoch 37, Training Accuracy: 0.8697916666666666, Validation Accuracy: 0.90625\n","Epoch 38, Training Loss: 0.3601653344101376, Validation Loss: 0.30233830213546753\n","Epoch 38, Training Accuracy: 0.8489583333333334, Validation Accuracy: 0.890625\n","Epoch 39, Training Loss: 0.30503632293807137, Validation Loss: 0.3357568383216858\n","Epoch 39, Training Accuracy: 0.8784722222222222, Validation Accuracy: 0.890625\n","Epoch 40, Training Loss: 0.31783582435713875, Validation Loss: 0.41281378269195557\n","Epoch 40, Training Accuracy: 0.8697916666666666, Validation Accuracy: 0.796875\n","Epoch 41, Training Loss: 0.3086044258541531, Validation Loss: 0.38605815172195435\n","Epoch 41, Training Accuracy: 0.8854166666666666, Validation Accuracy: 0.84375\n","Epoch 42, Training Loss: 0.2754079219367769, Validation Loss: 0.2785366177558899\n","Epoch 42, Training Accuracy: 0.90625, Validation Accuracy: 0.890625\n","Epoch 43, Training Loss: 0.3051300644874573, Validation Loss: 0.3809243440628052\n","Epoch 43, Training Accuracy: 0.8819444444444444, Validation Accuracy: 0.796875\n","Epoch 44, Training Loss: 0.3315969755252202, Validation Loss: 0.33335059881210327\n","Epoch 44, Training Accuracy: 0.8559027777777778, Validation Accuracy: 0.859375\n","Epoch 45, Training Loss: 0.3249926533963945, Validation Loss: 0.2884768843650818\n","Epoch 45, Training Accuracy: 0.8645833333333334, Validation Accuracy: 0.90625\n","Epoch 46, Training Loss: 0.2946131279071172, Validation Loss: 0.29896441102027893\n","Epoch 46, Training Accuracy: 0.8767361111111112, Validation Accuracy: 0.859375\n","Epoch 47, Training Loss: 0.26556669506761765, Validation Loss: 0.28864365816116333\n","Epoch 47, Training Accuracy: 0.8888888888888888, Validation Accuracy: 0.890625\n","Epoch 48, Training Loss: 0.2655781822072135, Validation Loss: 0.36660853028297424\n","Epoch 48, Training Accuracy: 0.8975694444444444, Validation Accuracy: 0.859375\n","Epoch 49, Training Loss: 0.26310083601209855, Validation Loss: 0.317480206489563\n","Epoch 49, Training Accuracy: 0.8888888888888888, Validation Accuracy: 0.875\n","Epoch 50, Training Loss: 0.21550022231207955, Validation Loss: 0.3250138461589813\n","Epoch 50, Training Accuracy: 0.9270833333333334, Validation Accuracy: 0.84375\n","Epoch 51, Training Loss: 0.2500540398889118, Validation Loss: 0.26401519775390625\n","Epoch 51, Training Accuracy: 0.8975694444444444, Validation Accuracy: 0.921875\n","Epoch 52, Training Loss: 0.283830679125256, Validation Loss: 0.37408554553985596\n","Epoch 52, Training Accuracy: 0.8784722222222222, Validation Accuracy: 0.828125\n","Epoch 53, Training Loss: 0.26688788996802437, Validation Loss: 0.36480093002319336\n","Epoch 53, Training Accuracy: 0.8923611111111112, Validation Accuracy: 0.84375\n","Epoch 54, Training Loss: 0.250938539703687, Validation Loss: 0.26547253131866455\n","Epoch 54, Training Accuracy: 0.9149305555555556, Validation Accuracy: 0.921875\n","Epoch 55, Training Loss: 0.23745771249135336, Validation Loss: 0.25793221592903137\n","Epoch 55, Training Accuracy: 0.9097222222222222, Validation Accuracy: 0.921875\n","Epoch 56, Training Loss: 0.23332608077261183, Validation Loss: 0.25144124031066895\n","Epoch 56, Training Accuracy: 0.9045138888888888, Validation Accuracy: 0.921875\n","Epoch 57, Training Loss: 0.24475761420196956, Validation Loss: 0.2562825381755829\n","Epoch 57, Training Accuracy: 0.9010416666666666, Validation Accuracy: 0.90625\n","Epoch 58, Training Loss: 0.31698812709914315, Validation Loss: 0.2945491075515747\n","Epoch 58, Training Accuracy: 0.8576388888888888, Validation Accuracy: 0.859375\n","Epoch 59, Training Loss: 0.3240403996573554, Validation Loss: 0.3403984606266022\n","Epoch 59, Training Accuracy: 0.8628472222222222, Validation Accuracy: 0.921875\n","Epoch 60, Training Loss: 0.2664540476269192, Validation Loss: 0.29196977615356445\n","Epoch 60, Training Accuracy: 0.9097222222222222, Validation Accuracy: 0.828125\n","Epoch 61, Training Loss: 0.21768956714206272, Validation Loss: 0.2389022409915924\n","Epoch 61, Training Accuracy: 0.9253472222222222, Validation Accuracy: 0.90625\n","Epoch 62, Training Loss: 0.1968116263548533, Validation Loss: 0.3085554242134094\n","Epoch 62, Training Accuracy: 0.9375, Validation Accuracy: 0.828125\n","Epoch 63, Training Loss: 0.21437868972619376, Validation Loss: 0.33547425270080566\n","Epoch 63, Training Accuracy: 0.9184027777777778, Validation Accuracy: 0.859375\n","Epoch 64, Training Loss: 0.2002041372987959, Validation Loss: 0.2619505822658539\n","Epoch 64, Training Accuracy: 0.9392361111111112, Validation Accuracy: 0.84375\n","Epoch 65, Training Loss: 0.16652733004755443, Validation Loss: 0.24720242619514465\n","Epoch 65, Training Accuracy: 0.9583333333333334, Validation Accuracy: 0.90625\n","Epoch 66, Training Loss: 0.1565442896551556, Validation Loss: 0.2497745007276535\n","Epoch 66, Training Accuracy: 0.9565972222222222, Validation Accuracy: 0.890625\n","Epoch 67, Training Loss: 0.13493484755357107, Validation Loss: 0.20845015347003937\n","Epoch 67, Training Accuracy: 0.9774305555555556, Validation Accuracy: 0.96875\n","Epoch 68, Training Loss: 0.1611908334824774, Validation Loss: 0.2249181568622589\n","Epoch 68, Training Accuracy: 0.9565972222222222, Validation Accuracy: 0.921875\n","Epoch 69, Training Loss: 0.15264414333634907, Validation Loss: 0.31002914905548096\n","Epoch 69, Training Accuracy: 0.9618055555555556, Validation Accuracy: 0.90625\n","Epoch 70, Training Loss: 0.16860533754030863, Validation Loss: 0.21056675910949707\n","Epoch 70, Training Accuracy: 0.9461805555555556, Validation Accuracy: 0.90625\n","Epoch 71, Training Loss: 0.16078177011675304, Validation Loss: 0.23574697971343994\n","Epoch 71, Training Accuracy: 0.9583333333333334, Validation Accuracy: 0.890625\n","Epoch 72, Training Loss: 0.14616856806808048, Validation Loss: 0.3186110258102417\n","Epoch 72, Training Accuracy: 0.9652777777777778, Validation Accuracy: 0.84375\n","Epoch 73, Training Loss: 0.14999278883139291, Validation Loss: 0.21111078560352325\n","Epoch 73, Training Accuracy: 0.9583333333333334, Validation Accuracy: 0.921875\n","Epoch 74, Training Loss: 0.13471957047780356, Validation Loss: 0.1735904961824417\n","Epoch 74, Training Accuracy: 0.9704861111111112, Validation Accuracy: 0.953125\n","Epoch 75, Training Loss: 0.13941334187984467, Validation Loss: 0.26574933528900146\n","Epoch 75, Training Accuracy: 0.9739583333333334, Validation Accuracy: 0.875\n","Epoch 76, Training Loss: 0.14249363789955774, Validation Loss: 0.3470834493637085\n","Epoch 76, Training Accuracy: 0.9722222222222222, Validation Accuracy: 0.859375\n","Epoch 77, Training Loss: 0.12282243288225597, Validation Loss: 0.18997767567634583\n","Epoch 77, Training Accuracy: 0.9791666666666666, Validation Accuracy: 0.96875\n","Epoch 78, Training Loss: 0.12894916948344973, Validation Loss: 0.49358490109443665\n","Epoch 78, Training Accuracy: 0.96875, Validation Accuracy: 0.765625\n","Epoch 79, Training Loss: 0.20987435513072544, Validation Loss: 0.23322007060050964\n","Epoch 79, Training Accuracy: 0.9253472222222222, Validation Accuracy: 0.921875\n","Epoch 80, Training Loss: 0.23291629718409645, Validation Loss: 0.2688469886779785\n","Epoch 80, Training Accuracy: 0.9010416666666666, Validation Accuracy: 0.921875\n","Epoch 81, Training Loss: 0.24640528526571062, Validation Loss: 0.2990953326225281\n","Epoch 81, Training Accuracy: 0.9097222222222222, Validation Accuracy: 0.921875\n","Epoch 82, Training Loss: 0.17984049684471554, Validation Loss: 0.3051156997680664\n","Epoch 82, Training Accuracy: 0.9548611111111112, Validation Accuracy: 0.90625\n","Epoch 83, Training Loss: 0.20302582449383205, Validation Loss: 0.3182312250137329\n","Epoch 83, Training Accuracy: 0.9270833333333334, Validation Accuracy: 0.890625\n","Epoch 84, Training Loss: 0.22253162331051296, Validation Loss: 0.2565283179283142\n","Epoch 84, Training Accuracy: 0.9149305555555556, Validation Accuracy: 0.921875\n","Epoch 85, Training Loss: 0.17179595761828953, Validation Loss: 0.27251991629600525\n","Epoch 85, Training Accuracy: 0.9565972222222222, Validation Accuracy: 0.890625\n","Epoch 86, Training Loss: 0.14378512816296685, Validation Loss: 0.18800275027751923\n","Epoch 86, Training Accuracy: 0.9618055555555556, Validation Accuracy: 0.9375\n","Epoch 87, Training Loss: 0.139275590578715, Validation Loss: 0.2964007258415222\n","Epoch 87, Training Accuracy: 0.9618055555555556, Validation Accuracy: 0.890625\n","Epoch 88, Training Loss: 0.12541834761699042, Validation Loss: 0.19231510162353516\n","Epoch 88, Training Accuracy: 0.9756944444444444, Validation Accuracy: 0.953125\n","Epoch 89, Training Loss: 0.11353001495202382, Validation Loss: 0.2164771556854248\n","Epoch 89, Training Accuracy: 0.9809027777777778, Validation Accuracy: 0.921875\n","Epoch 90, Training Loss: 0.09992999417914285, Validation Loss: 0.18789008259773254\n","Epoch 90, Training Accuracy: 0.9895833333333334, Validation Accuracy: 0.921875\n","Epoch 91, Training Loss: 0.09282797326644261, Validation Loss: 0.19381728768348694\n","Epoch 91, Training Accuracy: 0.9947916666666666, Validation Accuracy: 0.921875\n","Epoch 92, Training Loss: 0.09796034544706345, Validation Loss: 0.16620272397994995\n","Epoch 92, Training Accuracy: 0.9861111111111112, Validation Accuracy: 0.9375\n","Epoch 93, Training Loss: 0.09334609905878703, Validation Loss: 0.3036525249481201\n","Epoch 93, Training Accuracy: 0.9913194444444444, Validation Accuracy: 0.859375\n","Epoch 94, Training Loss: 0.0995307970378134, Validation Loss: 0.19469225406646729\n","Epoch 94, Training Accuracy: 0.9895833333333334, Validation Accuracy: 0.9375\n","Epoch 95, Training Loss: 0.09076388759745492, Validation Loss: 0.1491166651248932\n","Epoch 95, Training Accuracy: 0.9930555555555556, Validation Accuracy: 0.953125\n","Epoch 96, Training Loss: 0.12024097144603729, Validation Loss: 0.16713662445545197\n","Epoch 96, Training Accuracy: 0.96875, Validation Accuracy: 0.9375\n","Epoch 97, Training Loss: 0.12246603435940212, Validation Loss: 0.1764017641544342\n","Epoch 97, Training Accuracy: 0.9670138888888888, Validation Accuracy: 0.96875\n","Epoch 98, Training Loss: 0.11762926893101798, Validation Loss: 0.1839415431022644\n","Epoch 98, Training Accuracy: 0.9704861111111112, Validation Accuracy: 0.921875\n","Epoch 99, Training Loss: 0.11061290899912517, Validation Loss: 0.17000681161880493\n","Epoch 99, Training Accuracy: 0.9826388888888888, Validation Accuracy: 0.953125\n","Epoch 100, Training Loss: 0.11439469373888439, Validation Loss: 0.2012643814086914\n","Epoch 100, Training Accuracy: 0.9756944444444444, Validation Accuracy: 0.921875\n","Epoch 101, Training Loss: 0.1570880330271191, Validation Loss: 0.23768004775047302\n","Epoch 101, Training Accuracy: 0.9444444444444444, Validation Accuracy: 0.875\n","Epoch 102, Training Loss: 0.12629266911082798, Validation Loss: 0.2676786780357361\n","Epoch 102, Training Accuracy: 0.9756944444444444, Validation Accuracy: 0.890625\n","Epoch 103, Training Loss: 0.1425240288178126, Validation Loss: 0.19185471534729004\n","Epoch 103, Training Accuracy: 0.9583333333333334, Validation Accuracy: 0.9375\n","Epoch 104, Training Loss: 0.15143739763233396, Validation Loss: 0.1551671326160431\n","Epoch 104, Training Accuracy: 0.9635416666666666, Validation Accuracy: 0.953125\n","Epoch 105, Training Loss: 0.10218106624152926, Validation Loss: 0.21451789140701294\n","Epoch 105, Training Accuracy: 0.9913194444444444, Validation Accuracy: 0.9375\n","Epoch 106, Training Loss: 0.12161711562010977, Validation Loss: 0.2064802050590515\n","Epoch 106, Training Accuracy: 0.9704861111111112, Validation Accuracy: 0.953125\n","Epoch 107, Training Loss: 0.1065347981121805, Validation Loss: 0.17902147769927979\n","Epoch 107, Training Accuracy: 0.9930555555555556, Validation Accuracy: 0.953125\n","Epoch 108, Training Loss: 0.09287517186668184, Validation Loss: 0.1928580403327942\n","Epoch 108, Training Accuracy: 0.9895833333333334, Validation Accuracy: 0.953125\n","Epoch 109, Training Loss: 0.085280888610416, Validation Loss: 0.16055186092853546\n","Epoch 109, Training Accuracy: 0.9930555555555556, Validation Accuracy: 0.953125\n","Epoch 110, Training Loss: 0.08485332959228092, Validation Loss: 0.13894127309322357\n","Epoch 110, Training Accuracy: 0.9982638888888888, Validation Accuracy: 0.96875\n","Epoch 111, Training Loss: 0.09219099084536235, Validation Loss: 0.2005138248205185\n","Epoch 111, Training Accuracy: 0.9809027777777778, Validation Accuracy: 0.921875\n","Epoch 112, Training Loss: 0.09730926652749379, Validation Loss: 0.16870412230491638\n","Epoch 112, Training Accuracy: 0.9809027777777778, Validation Accuracy: 0.953125\n","Epoch 113, Training Loss: 0.0972942780289385, Validation Loss: 0.1848122924566269\n","Epoch 113, Training Accuracy: 0.9895833333333334, Validation Accuracy: 0.9375\n","Epoch 114, Training Loss: 0.07888725813892153, Validation Loss: 0.15730273723602295\n","Epoch 114, Training Accuracy: 0.9913194444444444, Validation Accuracy: 0.953125\n","Epoch 115, Training Loss: 0.0877690418726868, Validation Loss: 0.20685136318206787\n","Epoch 115, Training Accuracy: 0.9861111111111112, Validation Accuracy: 0.921875\n","Epoch 116, Training Loss: 0.07707014597124523, Validation Loss: 0.17813529074192047\n","Epoch 116, Training Accuracy: 0.9947916666666666, Validation Accuracy: 0.9375\n","Epoch 117, Training Loss: 0.08103168424632815, Validation Loss: 0.12462589144706726\n","Epoch 117, Training Accuracy: 0.9895833333333334, Validation Accuracy: 0.96875\n","Epoch 118, Training Loss: 0.06261701881885529, Validation Loss: 0.15183530747890472\n","Epoch 118, Training Accuracy: 1.0, Validation Accuracy: 0.921875\n","Epoch 119, Training Loss: 0.06880119608508216, Validation Loss: 0.26260632276535034\n","Epoch 119, Training Accuracy: 0.9913194444444444, Validation Accuracy: 0.859375\n","Epoch 120, Training Loss: 0.06348274565405315, Validation Loss: 0.1822662651538849\n","Epoch 120, Training Accuracy: 1.0, Validation Accuracy: 0.953125\n","Epoch 121, Training Loss: 0.05152667355206278, Validation Loss: 0.14718419313430786\n","Epoch 121, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 122, Training Loss: 0.05066932158337699, Validation Loss: 0.14978894591331482\n","Epoch 122, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 123, Training Loss: 0.049304567691352635, Validation Loss: 0.13378357887268066\n","Epoch 123, Training Accuracy: 0.9982638888888888, Validation Accuracy: 0.96875\n","Epoch 124, Training Loss: 0.07833540067076683, Validation Loss: 0.15090307593345642\n","Epoch 124, Training Accuracy: 0.9913194444444444, Validation Accuracy: 0.953125\n","Epoch 125, Training Loss: 0.07397932766212358, Validation Loss: 0.2006317377090454\n","Epoch 125, Training Accuracy: 0.9947916666666666, Validation Accuracy: 0.9375\n","Epoch 126, Training Loss: 0.11955183992783229, Validation Loss: 0.14642462134361267\n","Epoch 126, Training Accuracy: 0.9722222222222222, Validation Accuracy: 0.953125\n","Epoch 127, Training Loss: 0.14453306628598106, Validation Loss: 0.20286791026592255\n","Epoch 127, Training Accuracy: 0.9548611111111112, Validation Accuracy: 0.921875\n","Epoch 128, Training Loss: 0.13063021997610727, Validation Loss: 0.21355819702148438\n","Epoch 128, Training Accuracy: 0.9618055555555556, Validation Accuracy: 0.90625\n","Epoch 129, Training Loss: 0.12971586402919558, Validation Loss: 0.16196218132972717\n","Epoch 129, Training Accuracy: 0.9722222222222222, Validation Accuracy: 0.96875\n","Epoch 130, Training Loss: 0.10186126910977894, Validation Loss: 0.2830483019351959\n","Epoch 130, Training Accuracy: 0.9947916666666666, Validation Accuracy: 0.890625\n","Epoch 131, Training Loss: 0.08302133530378342, Validation Loss: 0.17720793187618256\n","Epoch 131, Training Accuracy: 0.9930555555555556, Validation Accuracy: 0.921875\n","Epoch 132, Training Loss: 0.06361751755078633, Validation Loss: 0.18335723876953125\n","Epoch 132, Training Accuracy: 1.0, Validation Accuracy: 0.921875\n","Epoch 133, Training Loss: 0.052587248384952545, Validation Loss: 0.14027616381645203\n","Epoch 133, Training Accuracy: 1.0, Validation Accuracy: 0.953125\n","Epoch 134, Training Loss: 0.052349271459711924, Validation Loss: 0.1569191962480545\n","Epoch 134, Training Accuracy: 0.9965277777777778, Validation Accuracy: 0.953125\n","Epoch 135, Training Loss: 0.042605213820934296, Validation Loss: 0.1347253918647766\n","Epoch 135, Training Accuracy: 1.0, Validation Accuracy: 0.9375\n","Epoch 136, Training Loss: 0.04574516539772352, Validation Loss: 0.15789204835891724\n","Epoch 136, Training Accuracy: 1.0, Validation Accuracy: 0.9375\n","Epoch 137, Training Loss: 0.04044504794809553, Validation Loss: 0.11372454464435577\n","Epoch 137, Training Accuracy: 0.9965277777777778, Validation Accuracy: 0.984375\n","Epoch 138, Training Loss: 0.05172207744585143, Validation Loss: 0.11982935667037964\n","Epoch 138, Training Accuracy: 0.9982638888888888, Validation Accuracy: 0.96875\n","Epoch 139, Training Loss: 0.0601569629377789, Validation Loss: 0.13341529667377472\n","Epoch 139, Training Accuracy: 0.9947916666666666, Validation Accuracy: 0.984375\n","Epoch 140, Training Loss: 0.061978397683964834, Validation Loss: 0.12551599740982056\n","Epoch 140, Training Accuracy: 0.9947916666666666, Validation Accuracy: 0.96875\n","Epoch 141, Training Loss: 0.08522094661990802, Validation Loss: 0.4026988744735718\n","Epoch 141, Training Accuracy: 0.9861111111111112, Validation Accuracy: 0.765625\n","Epoch 142, Training Loss: 0.08885407447814941, Validation Loss: 0.1918611228466034\n","Epoch 142, Training Accuracy: 0.984375, Validation Accuracy: 0.9375\n","Epoch 143, Training Loss: 0.08541184870733155, Validation Loss: 0.23200534284114838\n","Epoch 143, Training Accuracy: 0.9895833333333334, Validation Accuracy: 0.90625\n","Epoch 144, Training Loss: 0.09002576023340225, Validation Loss: 0.14680448174476624\n","Epoch 144, Training Accuracy: 0.9861111111111112, Validation Accuracy: 0.921875\n","Epoch 145, Training Loss: 0.08786549088027742, Validation Loss: 0.17537882924079895\n","Epoch 145, Training Accuracy: 0.9861111111111112, Validation Accuracy: 0.96875\n","Epoch 146, Training Loss: 0.06151830984486474, Validation Loss: 0.12102934718132019\n","Epoch 146, Training Accuracy: 0.9965277777777778, Validation Accuracy: 0.96875\n","Epoch 147, Training Loss: 0.06907556123203701, Validation Loss: 0.16885101795196533\n","Epoch 147, Training Accuracy: 0.9965277777777778, Validation Accuracy: 0.9375\n","Epoch 148, Training Loss: 0.06512782308790419, Validation Loss: 0.135483518242836\n","Epoch 148, Training Accuracy: 0.9947916666666666, Validation Accuracy: 0.96875\n","Epoch 149, Training Loss: 0.05196780007746485, Validation Loss: 0.2528117895126343\n","Epoch 149, Training Accuracy: 1.0, Validation Accuracy: 0.890625\n","Epoch 150, Training Loss: 0.048410565902789436, Validation Loss: 0.16708901524543762\n","Epoch 150, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 151, Training Loss: 0.04758828009168307, Validation Loss: 0.11675864458084106\n","Epoch 151, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 152, Training Loss: 0.04108088049623701, Validation Loss: 0.12925870716571808\n","Epoch 152, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 153, Training Loss: 0.06906126025650236, Validation Loss: 0.19110801815986633\n","Epoch 153, Training Accuracy: 0.9878472222222222, Validation Accuracy: 0.921875\n","Epoch 154, Training Loss: 0.0941333638297187, Validation Loss: 0.22816145420074463\n","Epoch 154, Training Accuracy: 0.9774305555555556, Validation Accuracy: 0.890625\n","Epoch 155, Training Loss: 0.09067504935794407, Validation Loss: 0.14037944376468658\n","Epoch 155, Training Accuracy: 0.9861111111111112, Validation Accuracy: 0.953125\n","Epoch 156, Training Loss: 0.08201604253715938, Validation Loss: 0.18579110503196716\n","Epoch 156, Training Accuracy: 0.9913194444444444, Validation Accuracy: 0.921875\n","Epoch 157, Training Loss: 0.05994794931676653, Validation Loss: 0.16917815804481506\n","Epoch 157, Training Accuracy: 0.9947916666666666, Validation Accuracy: 0.953125\n","Epoch 158, Training Loss: 0.053882521473699145, Validation Loss: 0.23860296607017517\n","Epoch 158, Training Accuracy: 1.0, Validation Accuracy: 0.875\n","Epoch 159, Training Loss: 0.07298800970117252, Validation Loss: 0.13987872004508972\n","Epoch 159, Training Accuracy: 0.9895833333333334, Validation Accuracy: 0.953125\n","Epoch 160, Training Loss: 0.08161572449737126, Validation Loss: 0.162368506193161\n","Epoch 160, Training Accuracy: 0.984375, Validation Accuracy: 0.9375\n","Epoch 161, Training Loss: 0.062499152289496526, Validation Loss: 0.17150387167930603\n","Epoch 161, Training Accuracy: 0.9930555555555556, Validation Accuracy: 0.96875\n","Epoch 162, Training Loss: 0.051365860634379916, Validation Loss: 0.12030886113643646\n","Epoch 162, Training Accuracy: 0.9982638888888888, Validation Accuracy: 0.984375\n","Epoch 163, Training Loss: 0.040791665100389056, Validation Loss: 0.09436432272195816\n","Epoch 163, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 164, Training Loss: 0.0359127020670308, Validation Loss: 0.15140244364738464\n","Epoch 164, Training Accuracy: 1.0, Validation Accuracy: 0.9375\n","Epoch 165, Training Loss: 0.0348413936379883, Validation Loss: 0.18283450603485107\n","Epoch 165, Training Accuracy: 1.0, Validation Accuracy: 0.953125\n","Epoch 166, Training Loss: 0.03335518762469292, Validation Loss: 0.12416970729827881\n","Epoch 166, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 167, Training Loss: 0.03212628492878543, Validation Loss: 0.13453826308250427\n","Epoch 167, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 168, Training Loss: 0.04027992321385278, Validation Loss: 0.09444164484739304\n","Epoch 168, Training Accuracy: 1.0, Validation Accuracy: 0.984375\n","Epoch 169, Training Loss: 0.03543017328613334, Validation Loss: 0.1177363321185112\n","Epoch 169, Training Accuracy: 1.0, Validation Accuracy: 0.984375\n","Epoch 170, Training Loss: 0.03733315132558346, Validation Loss: 0.1375356912612915\n","Epoch 170, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 171, Training Loss: 0.02732790240810977, Validation Loss: 0.09014388173818588\n","Epoch 171, Training Accuracy: 1.0, Validation Accuracy: 0.984375\n","Epoch 172, Training Loss: 0.02819872937268681, Validation Loss: 0.12667322158813477\n","Epoch 172, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 173, Training Loss: 0.03391801565885544, Validation Loss: 0.08953666687011719\n","Epoch 173, Training Accuracy: 1.0, Validation Accuracy: 1.0\n","Epoch 174, Training Loss: 0.0338967912313011, Validation Loss: 0.15182849764823914\n","Epoch 174, Training Accuracy: 1.0, Validation Accuracy: 0.921875\n","Epoch 175, Training Loss: 0.03632904982401265, Validation Loss: 0.14583900570869446\n","Epoch 175, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 176, Training Loss: 0.051597063119212784, Validation Loss: 0.10517533868551254\n","Epoch 176, Training Accuracy: 0.9965277777777778, Validation Accuracy: 0.984375\n","Epoch 177, Training Loss: 0.15364069491624832, Validation Loss: 0.2345203161239624\n","Epoch 177, Training Accuracy: 0.9548611111111112, Validation Accuracy: 0.90625\n","Epoch 178, Training Loss: 0.23455701768398285, Validation Loss: 0.35451215505599976\n","Epoch 178, Training Accuracy: 0.9114583333333334, Validation Accuracy: 0.84375\n","Epoch 179, Training Loss: 0.25195849272939896, Validation Loss: 0.20186427235603333\n","Epoch 179, Training Accuracy: 0.9027777777777778, Validation Accuracy: 0.953125\n","Epoch 180, Training Loss: 0.20265606045722961, Validation Loss: 0.22137987613677979\n","Epoch 180, Training Accuracy: 0.9427083333333334, Validation Accuracy: 0.953125\n","Epoch 181, Training Loss: 0.16531775560643938, Validation Loss: 0.2986752390861511\n","Epoch 181, Training Accuracy: 0.9565972222222222, Validation Accuracy: 0.875\n","Epoch 182, Training Loss: 0.1659588623378012, Validation Loss: 0.29135531187057495\n","Epoch 182, Training Accuracy: 0.9548611111111112, Validation Accuracy: 0.828125\n","Epoch 183, Training Loss: 0.14077859703037474, Validation Loss: 0.16897502541542053\n","Epoch 183, Training Accuracy: 0.9652777777777778, Validation Accuracy: 0.96875\n","Epoch 184, Training Loss: 0.11301130801439285, Validation Loss: 0.2159167230129242\n","Epoch 184, Training Accuracy: 0.9756944444444444, Validation Accuracy: 0.890625\n","Epoch 185, Training Loss: 0.08193105045292112, Validation Loss: 0.16315168142318726\n","Epoch 185, Training Accuracy: 0.9930555555555556, Validation Accuracy: 0.953125\n","Epoch 186, Training Loss: 0.06870783037609524, Validation Loss: 0.1307847499847412\n","Epoch 186, Training Accuracy: 0.9947916666666666, Validation Accuracy: 0.984375\n","Epoch 187, Training Loss: 0.05407358374860552, Validation Loss: 0.13179618120193481\n","Epoch 187, Training Accuracy: 1.0, Validation Accuracy: 0.953125\n","Epoch 188, Training Loss: 0.05086987093091011, Validation Loss: 0.11069716513156891\n","Epoch 188, Training Accuracy: 0.9982638888888888, Validation Accuracy: 0.984375\n","Epoch 189, Training Loss: 0.04766358559330305, Validation Loss: 0.14758312702178955\n","Epoch 189, Training Accuracy: 1.0, Validation Accuracy: 0.953125\n","Epoch 190, Training Loss: 0.05706018375025855, Validation Loss: 0.17569229006767273\n","Epoch 190, Training Accuracy: 0.9913194444444444, Validation Accuracy: 0.9375\n","Epoch 191, Training Loss: 0.049159290889898934, Validation Loss: 0.14754651486873627\n","Epoch 191, Training Accuracy: 1.0, Validation Accuracy: 0.953125\n","Epoch 192, Training Loss: 0.04152372810575697, Validation Loss: 0.16090111434459686\n","Epoch 192, Training Accuracy: 0.9982638888888888, Validation Accuracy: 0.921875\n","Epoch 193, Training Loss: 0.036798655365904175, Validation Loss: 0.11337362229824066\n","Epoch 193, Training Accuracy: 1.0, Validation Accuracy: 0.984375\n","Epoch 194, Training Loss: 0.030737735331058502, Validation Loss: 0.11195074021816254\n","Epoch 194, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 195, Training Loss: 0.0281869624223974, Validation Loss: 0.10625892877578735\n","Epoch 195, Training Accuracy: 1.0, Validation Accuracy: 0.984375\n","Epoch 196, Training Loss: 0.02946558760272132, Validation Loss: 0.09298647940158844\n","Epoch 196, Training Accuracy: 1.0, Validation Accuracy: 1.0\n","Epoch 197, Training Loss: 0.030883041934834585, Validation Loss: 0.1108861118555069\n","Epoch 197, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 198, Training Loss: 0.027946609382828076, Validation Loss: 0.08271049708127975\n","Epoch 198, Training Accuracy: 1.0, Validation Accuracy: 0.984375\n","Epoch 199, Training Loss: 0.02627680181629128, Validation Loss: 0.13145709037780762\n","Epoch 199, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 200, Training Loss: 0.024412796315219667, Validation Loss: 0.10422854870557785\n","Epoch 200, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 201, Training Loss: 0.029584715763727825, Validation Loss: 0.18275325000286102\n","Epoch 201, Training Accuracy: 1.0, Validation Accuracy: 0.953125\n","Epoch 202, Training Loss: 0.03425940602189965, Validation Loss: 0.14997856318950653\n","Epoch 202, Training Accuracy: 0.9982638888888888, Validation Accuracy: 0.9375\n","Epoch 203, Training Loss: 0.040417792896429695, Validation Loss: 0.1486353874206543\n","Epoch 203, Training Accuracy: 1.0, Validation Accuracy: 0.953125\n","Epoch 204, Training Loss: 0.04473966442876392, Validation Loss: 0.1564246565103531\n","Epoch 204, Training Accuracy: 0.9982638888888888, Validation Accuracy: 0.921875\n","Epoch 205, Training Loss: 0.06672525447275904, Validation Loss: 0.11468364298343658\n","Epoch 205, Training Accuracy: 0.9930555555555556, Validation Accuracy: 0.984375\n","Epoch 206, Training Loss: 0.07405274278587765, Validation Loss: 0.19318899512290955\n","Epoch 206, Training Accuracy: 0.9878472222222222, Validation Accuracy: 0.9375\n","Epoch 207, Training Loss: 0.07395773960484399, Validation Loss: 0.19401204586029053\n","Epoch 207, Training Accuracy: 0.9895833333333334, Validation Accuracy: 0.953125\n","Epoch 208, Training Loss: 0.07828308766086896, Validation Loss: 0.14615096151828766\n","Epoch 208, Training Accuracy: 0.9913194444444444, Validation Accuracy: 0.96875\n","Epoch 209, Training Loss: 0.06957653868529531, Validation Loss: 0.16361114382743835\n","Epoch 209, Training Accuracy: 0.9895833333333334, Validation Accuracy: 0.921875\n","Epoch 210, Training Loss: 0.06453799580534299, Validation Loss: 0.11610689759254456\n","Epoch 210, Training Accuracy: 0.9947916666666666, Validation Accuracy: 0.953125\n","Epoch 211, Training Loss: 0.0620862344900767, Validation Loss: 0.26292258501052856\n","Epoch 211, Training Accuracy: 0.9930555555555556, Validation Accuracy: 0.921875\n","Epoch 212, Training Loss: 0.07138986016313235, Validation Loss: 0.16978053748607635\n","Epoch 212, Training Accuracy: 0.9982638888888888, Validation Accuracy: 0.921875\n","Epoch 213, Training Loss: 0.05537611577245924, Validation Loss: 0.11426980793476105\n","Epoch 213, Training Accuracy: 1.0, Validation Accuracy: 0.984375\n","Epoch 214, Training Loss: 0.04559930869274669, Validation Loss: 0.13351662456989288\n","Epoch 214, Training Accuracy: 1.0, Validation Accuracy: 0.953125\n","Epoch 215, Training Loss: 0.033543164738350444, Validation Loss: 0.14882802963256836\n","Epoch 215, Training Accuracy: 1.0, Validation Accuracy: 0.953125\n","Epoch 216, Training Loss: 0.031497209436363645, Validation Loss: 0.13362401723861694\n","Epoch 216, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 217, Training Loss: 0.02612066910498672, Validation Loss: 0.12641803920269012\n","Epoch 217, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 218, Training Loss: 0.027102155817879572, Validation Loss: 0.1277380883693695\n","Epoch 218, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 219, Training Loss: 0.022765070406927004, Validation Loss: 0.14496980607509613\n","Epoch 219, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 220, Training Loss: 0.03140581047369374, Validation Loss: 0.14357006549835205\n","Epoch 220, Training Accuracy: 1.0, Validation Accuracy: 0.9375\n","Epoch 221, Training Loss: 0.02413918947180112, Validation Loss: 0.20756539702415466\n","Epoch 221, Training Accuracy: 1.0, Validation Accuracy: 0.9375\n","Epoch 222, Training Loss: 0.030078134396009974, Validation Loss: 0.13793832063674927\n","Epoch 222, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 223, Training Loss: 0.027690879586670134, Validation Loss: 0.09130045771598816\n","Epoch 223, Training Accuracy: 1.0, Validation Accuracy: 0.984375\n","Epoch 224, Training Loss: 0.026751953694555495, Validation Loss: 0.09866373240947723\n","Epoch 224, Training Accuracy: 1.0, Validation Accuracy: 1.0\n","Epoch 225, Training Loss: 0.0260461438447237, Validation Loss: 0.09177040308713913\n","Epoch 225, Training Accuracy: 1.0, Validation Accuracy: 1.0\n","Epoch 226, Training Loss: 0.025220987283521228, Validation Loss: 0.1501191258430481\n","Epoch 226, Training Accuracy: 1.0, Validation Accuracy: 0.953125\n","Epoch 227, Training Loss: 0.027894140117698245, Validation Loss: 0.21255987882614136\n","Epoch 227, Training Accuracy: 1.0, Validation Accuracy: 0.9375\n","Epoch 228, Training Loss: 0.028568069140116375, Validation Loss: 0.17008648812770844\n","Epoch 228, Training Accuracy: 1.0, Validation Accuracy: 0.921875\n","Epoch 229, Training Loss: 0.025840900631414518, Validation Loss: 0.09723478555679321\n","Epoch 229, Training Accuracy: 1.0, Validation Accuracy: 0.984375\n","Epoch 230, Training Loss: 0.026879231962892745, Validation Loss: 0.08510555326938629\n","Epoch 230, Training Accuracy: 1.0, Validation Accuracy: 0.984375\n","Epoch 231, Training Loss: 0.022390025150444772, Validation Loss: 0.07891545444726944\n","Epoch 231, Training Accuracy: 1.0, Validation Accuracy: 1.0\n","Epoch 232, Training Loss: 0.02238583606150415, Validation Loss: 0.16689340770244598\n","Epoch 232, Training Accuracy: 1.0, Validation Accuracy: 0.921875\n","Epoch 233, Training Loss: 0.022774251384867564, Validation Loss: 0.10199585556983948\n","Epoch 233, Training Accuracy: 1.0, Validation Accuracy: 0.984375\n","Epoch 234, Training Loss: 0.02617794730597072, Validation Loss: 0.16836220026016235\n","Epoch 234, Training Accuracy: 1.0, Validation Accuracy: 0.9375\n","Epoch 235, Training Loss: 0.047710347920656204, Validation Loss: 0.17876070737838745\n","Epoch 235, Training Accuracy: 0.9965277777777778, Validation Accuracy: 0.9375\n","Epoch 236, Training Loss: 0.06931608956721094, Validation Loss: 0.14581404626369476\n","Epoch 236, Training Accuracy: 0.9965277777777778, Validation Accuracy: 0.953125\n","Epoch 237, Training Loss: 0.11331168396605386, Validation Loss: 0.19919413328170776\n","Epoch 237, Training Accuracy: 0.9722222222222222, Validation Accuracy: 0.921875\n","Epoch 238, Training Loss: 0.11351229415999518, Validation Loss: 0.27297982573509216\n","Epoch 238, Training Accuracy: 0.9791666666666666, Validation Accuracy: 0.90625\n","Epoch 239, Training Loss: 0.12230852742989858, Validation Loss: 0.2088141292333603\n","Epoch 239, Training Accuracy: 0.9704861111111112, Validation Accuracy: 0.921875\n","Epoch 240, Training Loss: 0.10209719340006511, Validation Loss: 0.2788253426551819\n","Epoch 240, Training Accuracy: 0.9791666666666666, Validation Accuracy: 0.921875\n","Epoch 241, Training Loss: 0.08607011785109837, Validation Loss: 0.1500961035490036\n","Epoch 241, Training Accuracy: 0.984375, Validation Accuracy: 0.953125\n","Epoch 242, Training Loss: 0.07267772406339645, Validation Loss: 0.19626763463020325\n","Epoch 242, Training Accuracy: 0.9982638888888888, Validation Accuracy: 0.890625\n","Epoch 243, Training Loss: 0.05236752000119951, Validation Loss: 0.15632173418998718\n","Epoch 243, Training Accuracy: 0.9982638888888888, Validation Accuracy: 0.953125\n","Epoch 244, Training Loss: 0.0404604064921538, Validation Loss: 0.11071255803108215\n","Epoch 244, Training Accuracy: 1.0, Validation Accuracy: 1.0\n","Epoch 245, Training Loss: 0.04014618798262543, Validation Loss: 0.10018621385097504\n","Epoch 245, Training Accuracy: 0.9982638888888888, Validation Accuracy: 0.96875\n","Epoch 246, Training Loss: 0.031397991710238986, Validation Loss: 0.13961541652679443\n","Epoch 246, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 247, Training Loss: 0.026203375930587452, Validation Loss: 0.10128011554479599\n","Epoch 247, Training Accuracy: 1.0, Validation Accuracy: 0.984375\n","Epoch 248, Training Loss: 0.021688824105593894, Validation Loss: 0.13474693894386292\n","Epoch 248, Training Accuracy: 1.0, Validation Accuracy: 0.953125\n","Epoch 249, Training Loss: 0.020270756756265957, Validation Loss: 0.1583055555820465\n","Epoch 249, Training Accuracy: 1.0, Validation Accuracy: 0.953125\n","Epoch 250, Training Loss: 0.01906751272165113, Validation Loss: 0.1364145129919052\n","Epoch 250, Training Accuracy: 1.0, Validation Accuracy: 0.953125\n","Epoch 251, Training Loss: 0.020406127700375185, Validation Loss: 0.1006494015455246\n","Epoch 251, Training Accuracy: 1.0, Validation Accuracy: 0.984375\n","Epoch 252, Training Loss: 0.020108101682530508, Validation Loss: 0.0887799859046936\n","Epoch 252, Training Accuracy: 1.0, Validation Accuracy: 1.0\n","Epoch 253, Training Loss: 0.021880500639478367, Validation Loss: 0.11738284677267075\n","Epoch 253, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 254, Training Loss: 0.021447688962022465, Validation Loss: 0.09168173372745514\n","Epoch 254, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 255, Training Loss: 0.02145141839153237, Validation Loss: 0.13568925857543945\n","Epoch 255, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 256, Training Loss: 0.023854510030812688, Validation Loss: 0.12155579030513763\n","Epoch 256, Training Accuracy: 1.0, Validation Accuracy: 1.0\n","Epoch 257, Training Loss: 0.026710205814904638, Validation Loss: 0.15054042637348175\n","Epoch 257, Training Accuracy: 1.0, Validation Accuracy: 0.984375\n","Epoch 258, Training Loss: 0.02757219411432743, Validation Loss: 0.13349439203739166\n","Epoch 258, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 259, Training Loss: 0.03452474934359392, Validation Loss: 0.2311735451221466\n","Epoch 259, Training Accuracy: 1.0, Validation Accuracy: 0.890625\n","Epoch 260, Training Loss: 0.03951512587567171, Validation Loss: 0.13387137651443481\n","Epoch 260, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 261, Training Loss: 0.046970945265558034, Validation Loss: 0.1676524579524994\n","Epoch 261, Training Accuracy: 0.9965277777777778, Validation Accuracy: 0.953125\n","Epoch 262, Training Loss: 0.03466378628379769, Validation Loss: 0.18089109659194946\n","Epoch 262, Training Accuracy: 1.0, Validation Accuracy: 0.953125\n","Epoch 263, Training Loss: 0.03060789220035076, Validation Loss: 0.11527332663536072\n","Epoch 263, Training Accuracy: 1.0, Validation Accuracy: 0.984375\n","Epoch 264, Training Loss: 0.024962620809674263, Validation Loss: 0.1307658851146698\n","Epoch 264, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 265, Training Loss: 0.022163380765252642, Validation Loss: 0.1692763864994049\n","Epoch 265, Training Accuracy: 1.0, Validation Accuracy: 0.953125\n","Epoch 266, Training Loss: 0.01784342930962642, Validation Loss: 0.09319765120744705\n","Epoch 266, Training Accuracy: 1.0, Validation Accuracy: 1.0\n","Epoch 267, Training Loss: 0.01727438097198804, Validation Loss: 0.11564472317695618\n","Epoch 267, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 268, Training Loss: 0.01763299231727918, Validation Loss: 0.12144264578819275\n","Epoch 268, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 269, Training Loss: 0.020719182988007862, Validation Loss: 0.14311477541923523\n","Epoch 269, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 270, Training Loss: 0.024676156126790576, Validation Loss: 0.13667763769626617\n","Epoch 270, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 271, Training Loss: 0.022338382278879482, Validation Loss: 0.13840383291244507\n","Epoch 271, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 272, Training Loss: 0.027076977408594556, Validation Loss: 0.13629230856895447\n","Epoch 272, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 273, Training Loss: 0.04684879527323776, Validation Loss: 0.18850719928741455\n","Epoch 273, Training Accuracy: 0.9982638888888888, Validation Accuracy: 0.890625\n","Epoch 274, Training Loss: 0.19094445059696832, Validation Loss: 0.30930206179618835\n","Epoch 274, Training Accuracy: 0.9253472222222222, Validation Accuracy: 0.890625\n","Epoch 275, Training Loss: 0.31893738773134017, Validation Loss: 0.30259212851524353\n","Epoch 275, Training Accuracy: 0.8611111111111112, Validation Accuracy: 0.796875\n","Epoch 276, Training Loss: 0.2628418306509654, Validation Loss: 0.26971006393432617\n","Epoch 276, Training Accuracy: 0.9114583333333334, Validation Accuracy: 0.890625\n","Epoch 277, Training Loss: 0.18349621444940567, Validation Loss: 0.24043802917003632\n","Epoch 277, Training Accuracy: 0.953125, Validation Accuracy: 0.921875\n","Epoch 278, Training Loss: 0.1320928724275695, Validation Loss: 0.2788717746734619\n","Epoch 278, Training Accuracy: 0.984375, Validation Accuracy: 0.90625\n","Epoch 279, Training Loss: 0.11149244258801143, Validation Loss: 0.22102324664592743\n","Epoch 279, Training Accuracy: 0.9826388888888888, Validation Accuracy: 0.90625\n","Epoch 280, Training Loss: 0.07847886325584517, Validation Loss: 0.1730859875679016\n","Epoch 280, Training Accuracy: 0.9947916666666666, Validation Accuracy: 0.9375\n","Epoch 281, Training Loss: 0.06200480585296949, Validation Loss: 0.17497314512729645\n","Epoch 281, Training Accuracy: 1.0, Validation Accuracy: 0.9375\n","Epoch 282, Training Loss: 0.060099612921476364, Validation Loss: 0.2098025232553482\n","Epoch 282, Training Accuracy: 0.9965277777777778, Validation Accuracy: 0.9375\n","Epoch 283, Training Loss: 0.04799130103654332, Validation Loss: 0.153726726770401\n","Epoch 283, Training Accuracy: 0.9982638888888888, Validation Accuracy: 0.921875\n","Epoch 284, Training Loss: 0.03830121933586068, Validation Loss: 0.14378610253334045\n","Epoch 284, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 285, Training Loss: 0.035218058774868645, Validation Loss: 0.1781845986843109\n","Epoch 285, Training Accuracy: 1.0, Validation Accuracy: 0.921875\n","Epoch 286, Training Loss: 0.03515903651714325, Validation Loss: 0.18663814663887024\n","Epoch 286, Training Accuracy: 1.0, Validation Accuracy: 0.921875\n","Epoch 287, Training Loss: 0.03447835250861115, Validation Loss: 0.19599348306655884\n","Epoch 287, Training Accuracy: 1.0, Validation Accuracy: 0.9375\n","Epoch 288, Training Loss: 0.0320125108377801, Validation Loss: 0.2470259666442871\n","Epoch 288, Training Accuracy: 0.9982638888888888, Validation Accuracy: 0.890625\n","Epoch 289, Training Loss: 0.045315114988221064, Validation Loss: 0.13993288576602936\n","Epoch 289, Training Accuracy: 0.9982638888888888, Validation Accuracy: 0.953125\n","Epoch 290, Training Loss: 0.03766076308157709, Validation Loss: 0.13712599873542786\n","Epoch 290, Training Accuracy: 0.9982638888888888, Validation Accuracy: 0.953125\n","Epoch 291, Training Loss: 0.03417032563851939, Validation Loss: 0.11579759418964386\n","Epoch 291, Training Accuracy: 1.0, Validation Accuracy: 0.96875\n","Epoch 292, Training Loss: 0.03277409656180276, Validation Loss: 0.13194169104099274\n","Epoch 292, Training Accuracy: 1.0, Validation Accuracy: 0.953125\n","Epoch 293, Training Loss: 0.031015226617455482, Validation Loss: 0.11547510325908661\n","Epoch 293, Training Accuracy: 1.0, Validation Accuracy: 0.984375\n","Epoch 294, Training Loss: 0.021964052899016276, Validation Loss: 0.13651207089424133\n","Epoch 294, Training Accuracy: 1.0, Validation Accuracy: 0.953125\n","Epoch 295, Training Loss: 0.02080077740053336, Validation Loss: 0.15874528884887695\n","Epoch 295, Training Accuracy: 1.0, Validation Accuracy: 0.953125\n","Epoch 296, Training Loss: 0.024796129307813115, Validation Loss: 0.14189821481704712\n","Epoch 296, Training Accuracy: 1.0, Validation Accuracy: 0.953125\n","Epoch 297, Training Loss: 0.029659719516833622, Validation Loss: 0.257246732711792\n","Epoch 297, Training Accuracy: 1.0, Validation Accuracy: 0.90625\n","Epoch 298, Training Loss: 0.03731580844355954, Validation Loss: 0.0992400050163269\n","Epoch 298, Training Accuracy: 1.0, Validation Accuracy: 1.0\n","Epoch 299, Training Loss: 0.028732357546687126, Validation Loss: 0.10386932641267776\n","Epoch 299, Training Accuracy: 1.0, Validation Accuracy: 0.984375\n","Epoch 300, Training Loss: 0.02773005473944876, Validation Loss: 0.08567649126052856\n","Epoch 300, Training Accuracy: 1.0, Validation Accuracy: 1.0\n","Finished Training\n"]}],"source":["# InceptionTime model\n","\n","# Loss and optimization\n","# 'device' sets which computing unit will be used, GPU(cuda) is preferred,\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# 'criterion' specifies the method to compute loss (an 'error' metric for model prediction)\n","#criterion = nn.CrossEntropyLoss().to(device)\n","criterion = nn.BCEWithLogitsLoss().to(device)#BCEWithLogitsLoss is the same as BCE, but with a sigmoid layer added before the BCE\n","\n","# 'optimizer' sets the algorithm that is used to adjust the weights of the model\n","# Here we use ADAM, which is a fairly popular optimization algo\n","# 'lr' means Learning Rate, which modulates how fast the weights are adjusted\n","optimizer = torch.optim.Adam(InceptionTime.parameters(), lr=0.001, weight_decay=0.01) #weight_decay is a regularization parameter\n","\n","# .to(device) simply means whe are directing this to the GPU or CPU (chosen above)\n","InceptionTime = InceptionTime.to(device)\n","threshold = 0 \n","\n","\"\"\" # Load the model from a saved point if exists\n","try:\n","    InceptionTime.load_state_dict(torch.load('best_model.pth'))\n","    print(\"Model loaded successfully\")\n","except FileNotFoundError:\n","    print(\"No saved model found, starting training from scratch\")\n"," \"\"\"\n"," \n"," # Initialize training losses, validation losses and accuracies\n","train_losses = []\n","val_losses = []\n","train_accuracies = []\n","val_accuracies = []\n","\n","\n","\n","####### Training loop #######\n","\n","# min_val_loss will be used to save the model with best performance (lowest loss)\n","min_val_loss = np.inf\n","# patience defines how many epochs without improvement will be tolerated before early stopping\n","patience = 150\n","patience_counter = 0\n","\n","# Training loop\n","# epoch is each training step\n","for epoch in range(300):\n","    # initialize single evaluation metrics (for this iteration)\n","    running_loss = 0.0\n","    running_accuracy = 0.0\n","    # receive inputs and labels from the training dataloader\n","    for i, data in enumerate(train_loader, 0):\n","        # send inputs and labels to device\n","        inputs, labels = data[0].to(device), data[1].to(device)\n","        # clear out the gradients of all parameters that the optimizer is tracking\n","        optimizer.zero_grad()\n","        # make model predictions\n","        outputs = InceptionTime(inputs).squeeze()\n","        # compute training loss based on predicted values\n","        loss = criterion(outputs, labels)\n","        # perform back propagation\n","        loss.backward()\n","        # apply optimizer to adjust the weights\n","        optimizer.step()\n","        \n","        # compute accuracy and store this epoch's loss\n","        predicted = outputs.detach().cpu().numpy()\n","        running_accuracy += accuracy_score(labels.cpu().numpy(), (predicted > threshold).astype(int))\n","        running_loss += loss.item()\n","\n","    # Validation loss computation\n","    val_running_loss = 0.0\n","    val_running_accuracy = 0.0\n","    # receive inputs and labels from the validation dataloader\n","    for i, data in enumerate(val_loader, 0):\n","        # send inputs and labels to device\n","        inputs, labels = data[0].to(device), data[1].to(device)\n","        # make model predictions\n","        outputs = InceptionTime(inputs).squeeze()\n","        \n","        # compute accuracy and store this epoch's loss\n","        predicted = outputs.detach().cpu().numpy()\n","        val_running_accuracy += accuracy_score(labels.cpu().numpy(), (predicted > threshold).astype(int))\n","        val_loss = criterion(outputs, labels)\n","        val_running_loss += val_loss.item()\n","        \n","    # accuracy and loss are computed based on the size of the batch (e.g. % of correct outputs)    \n","    train_accuracies.append(running_accuracy / len(train_loader))\n","    val_accuracies.append(val_running_accuracy / len(val_loader))\n","    train_losses.append(running_loss / len(train_loader))\n","    val_losses.append(val_running_loss / len(val_loader))\n","    \n","    # save the model if it has the best performance so far\n","    if val_loss < min_val_loss:\n","        # Save the model\n","        torch.save(InceptionTime.state_dict(), 'best_model.pth')\n","        min_val_loss = val_loss\n","\n","        patience_counter = 0  # Reset the patience counter\n","    else:\n","        # Increment the patience counter\n","        patience_counter += 1\n","# Check if we've run out of patience\n","    if patience_counter >= patience:\n","        print(\"Early stopping...\")\n","        break\n","        \n","    # Save the model every 50 epochs\n","    if epoch % 50 == 0:\n","        torch.save(InceptionTime.state_dict(), f'InceptionTime_model_epoch_{epoch}.pth')\n","\n","    \n","\n","    print(f'Epoch {epoch+1}, Training Loss: {running_loss / len(train_loader)}, Validation Loss: {val_running_loss / len(val_loader)}')\n","    print(f'Epoch {epoch+1}, Training Accuracy: {running_accuracy / len(train_loader)}, Validation Accuracy: {val_running_accuracy / len(val_loader)}')\n","\n","\n","print('Finished Training')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-28T19:50:16.729051Z","iopub.status.busy":"2023-08-28T19:50:16.728620Z","iopub.status.idle":"2023-08-28T19:50:16.756961Z","shell.execute_reply":"2023-08-28T19:50:16.755917Z","shell.execute_reply.started":"2023-08-28T19:50:16.729015Z"},"trusted":true},"outputs":[],"source":["# Save the InceptionTime model\n","#torch.save(InceptionTime.state_dict(), 'InceptionTime_model_80%Train.pth')\n","\n","# Load the model from a file\n","#InceptionTime.load_state_dict(torch.load('InceptionTime_model_epoch_250.pth'))\n","\n","# CPU-only machine with GPU-trained model\n","#InceptionTime.load_state_dict(torch.load('InceptionTime_model_epoch_300.pth',map_location=torch.device('cpu')))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Plotting model performance"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T13:38:38.410006Z","iopub.status.busy":"2023-08-29T13:38:38.409462Z","iopub.status.idle":"2023-08-29T13:38:38.535669Z","shell.execute_reply":"2023-08-29T13:38:38.534319Z","shell.execute_reply.started":"2023-08-29T13:38:38.409959Z"},"trusted":true},"outputs":[],"source":["# Plot the results\n","plt.figure(figsize=(12, 8))\n","plt.subplot(2, 2, 1)\n","plt.plot(train_losses, label='Training loss')\n","plt.plot(val_losses, label='Validation loss')\n","plt.legend()\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","\n","plt.subplot(2, 2, 2)\n","plt.plot(train_accuracies, label='Training accuracy')\n","plt.plot(val_accuracies, label='Validation accuracy')\n","plt.legend()\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","\n","plt.show()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Create submission file using model predictions"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T13:42:24.009975Z","iopub.status.busy":"2023-08-29T13:42:24.008961Z","iopub.status.idle":"2023-08-29T13:42:24.071089Z","shell.execute_reply":"2023-08-29T13:42:24.069898Z","shell.execute_reply.started":"2023-08-29T13:42:24.009920Z"},"trusted":true},"outputs":[],"source":["# Test the model on the validation dataset\n","\n","InceptionTime.eval()\n","\n","with torch.no_grad():\n","        y_pred = InceptionTime(tensor_x_val.to(device)).cpu().numpy()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Test the accuracy of model predictions in the validation dataset"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T13:45:36.786057Z","iopub.status.busy":"2023-08-29T13:45:36.784844Z","iopub.status.idle":"2023-08-29T13:45:36.797584Z","shell.execute_reply":"2023-08-29T13:45:36.795974Z","shell.execute_reply.started":"2023-08-29T13:45:36.786012Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(112, 1)\n","55\n","0.972972972972973\n","0.9732142857142857\n"]}],"source":["#print(y_pred)\n","print(y_pred.shape)\n","\n","# assign 1 when y_pred > 0 and 0 otherwise\n","predictions = (y_pred > -1).astype(int)\n","\n","print(len(predictions[predictions>0]))\n","\n","print(f1_score(y_val, predictions))\n","print(accuracy_score(y_val, predictions))"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T13:46:37.968624Z","iopub.status.busy":"2023-08-29T13:46:37.968211Z","iopub.status.idle":"2023-08-29T13:46:38.118612Z","shell.execute_reply":"2023-08-29T13:46:38.117072Z","shell.execute_reply.started":"2023-08-29T13:46:37.968588Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["4\n"]}],"source":["# Load the test set\n","X_test = np.load('test_set.npy')\n","\n","\n","# Convert to tensor\n","tensor_x_test = torch.Tensor(X_test)\n","\n","\n","# Get model predictions\n","InceptionTime.eval()\n","with torch.no_grad():\n","    y_pred = InceptionTime(tensor_x_test.to(device)).cpu().numpy()\n","\n","\n","predictions = (y_pred > -1).astype(int).squeeze()\n","#predictions = np.argmax(y_pred, axis=1)\n","print(len(predictions[predictions>0]))"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T13:52:18.707495Z","iopub.status.busy":"2023-08-29T13:52:18.707067Z","iopub.status.idle":"2023-08-29T13:52:18.718538Z","shell.execute_reply":"2023-08-29T13:52:18.717011Z","shell.execute_reply.started":"2023-08-29T13:52:18.707456Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["124\n"]}],"source":["predictions = (y_pred > -3.9).astype(int).squeeze()\n","\n","# Create submission file\n","with open(\"submission.csv\", \"w\") as f:\n","    f.write(\"win_id,label\\n\")\n","    for i, pred in enumerate(predictions):\n","        f.write(f\"{i},{pred}\\n\")\n","        \n","print(len(predictions[predictions>0]))"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2023-08-28T19:56:37.823852Z","iopub.status.busy":"2023-08-28T19:56:37.822783Z","iopub.status.idle":"2023-08-28T19:56:37.893084Z","shell.execute_reply":"2023-08-28T19:56:37.891908Z","shell.execute_reply.started":"2023-08-28T19:56:37.823807Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5918a17d18bc44dfb780620fb88082f1","version_major":2,"version_minor":0},"text/plain":["Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"]},"metadata":{},"output_type":"display_data"}],"source":["# Plot the average time series of each channel (2nd dimension) of tensor_x_val and tensor_x_test\n","\n","# Convert tensors to numpy arrays\n","tensor_x_val_plt = tensor_x_val.numpy()\n","tensor_x_test_plt = tensor_x_test.numpy()\n","\n","# Using a subplot for each channel\n","plt.figure(figsize=(12,6))\n","plt.subplot(2, 2, 1)\n","plt.title('M1 electrode')\n","plt.plot(np.squeeze(np.mean(tensor_x_val_plt[:,0,:], axis=0)), label='tensor_x_val')\n","plt.plot(np.squeeze(np.mean(tensor_x_test_plt[:,0,:], axis=0)), label='tensor_x_test')\n","plt.legend()\n","plt.xlabel('Time [s]')\n","plt.ylabel('Amplitude')\n","\n","plt.subplot(2, 2, 2)\n","plt.title('VA electrode')\n","plt.plot(np.squeeze(np.mean(tensor_x_val_plt[:,1,:], axis=0)), label='tensor_x_val')\n","plt.plot(np.squeeze(np.mean(tensor_x_test_plt[:,1,:], axis=0)), label='tensor_x_test')\n","plt.legend()\n","plt.xlabel('Time [s]')\n","plt.ylabel('Amplitude')\n","\n","plt.show()\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":4}
